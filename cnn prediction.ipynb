{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3y+775+pP+dloLXRZNY3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupojuharshita/Lane-Detection/blob/main/cnn%20prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LP9EFfPCCir",
        "outputId": "36838e84-8be8-48af-e661-437aaf1e83ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Unzipped /content/combined_dataset.zip to /content/combined_dataset\n",
            "Epoch 1, Loss: 77.4182\n",
            "Epoch 2, Loss: 73.5788\n",
            "Epoch 3, Loss: 72.4825\n",
            "Epoch 4, Loss: 71.6928\n",
            "Epoch 5, Loss: 71.3041\n",
            "Epoch 6, Loss: 71.0284\n",
            "Epoch 7, Loss: 70.8140\n",
            "Epoch 8, Loss: 70.6379\n",
            "Epoch 9, Loss: 70.5051\n",
            "Epoch 10, Loss: 70.3897\n",
            "Epoch 11, Loss: 70.3002\n",
            "Epoch 12, Loss: 70.1524\n",
            "Epoch 13, Loss: 70.1709\n",
            "Epoch 14, Loss: 70.0457\n",
            "Epoch 15, Loss: 69.9591\n",
            "Epoch 16, Loss: 69.9196\n",
            "Epoch 17, Loss: 69.8221\n",
            "Epoch 18, Loss: 69.7839\n",
            "Epoch 19, Loss: 69.7501\n",
            "Epoch 20, Loss: 69.6787\n",
            "Epoch 21, Loss: 69.5966\n",
            "Epoch 22, Loss: 69.5763\n",
            "Epoch 23, Loss: 69.6031\n",
            "Epoch 24, Loss: 69.5758\n",
            "Epoch 25, Loss: 69.5187\n",
            "Epoch 26, Loss: 69.4521\n",
            "Epoch 27, Loss: 69.3790\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Complete Code with Noise Reduction and Clear Visualization\n",
        "# -----------------------------\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Unzip Combined Dataset\n",
        "# -----------------------------\n",
        "zip_path = \"/content/combined_dataset.zip\"\n",
        "extract_path = \"/content/combined_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"✅ Unzipped {zip_path} to {extract_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Custom Dataset for Combined Images\n",
        "# -----------------------------\n",
        "class CombinedLaneDataset(Dataset):\n",
        "    def __init__(self, combined_dir):\n",
        "        self.combined_dir = combined_dir\n",
        "        self.frame_names = sorted(os.listdir(combined_dir))\n",
        "\n",
        "        self.input_transform = transforms.Compose([\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "        self.output_transform = transforms.Compose([\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        combined_path = os.path.join(self.combined_dir, self.frame_names[idx])\n",
        "        combined_image = Image.open(combined_path).convert('RGB')\n",
        "\n",
        "        w, h = combined_image.size\n",
        "        input_image = combined_image.crop((0, 0, w // 2, h))\n",
        "        output_image = combined_image.crop((w // 2, 0, w, h)).convert('L')\n",
        "\n",
        "        input_tensor = self.input_transform(input_image)\n",
        "        output_tensor = self.output_transform(output_image)\n",
        "\n",
        "        # Ensure the mask has only 1 channel\n",
        "        if output_tensor.shape[0] != 1:\n",
        "            output_tensor = output_tensor[0].unsqueeze(0)\n",
        "\n",
        "        return input_tensor, output_tensor\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Simple CNN Model for Lane Detection\n",
        "# -----------------------------\n",
        "class LaneCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LaneCNN, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 2, stride=2), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 2, stride=2), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Data Preparation\n",
        "# -----------------------------\n",
        "dataset = CombinedLaneDataset(extract_path)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Model Setup\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LaneCNN().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Training Loop\n",
        "# -----------------------------\n",
        "for epoch in range(30):  # Increase to 20 epochs\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 7. IoU Accuracy Calculation\n",
        "# -----------------------------\n",
        "def compute_iou(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    targets = targets > 0.5\n",
        "    intersection = (preds & targets).sum().item()\n",
        "    union = (preds | targets).sum().item()\n",
        "    return intersection / union if union != 0 else 1.0\n",
        "\n",
        "total_iou = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        preds = model(inputs)\n",
        "        total_iou += compute_iou(preds.cpu() > 0.5, targets.cpu() > 0.5)\n",
        "\n",
        "print(f\"Mean IoU Accuracy: {total_iou / len(train_loader):.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Visualization with Noise Removal\n",
        "# -----------------------------\n",
        "model.eval()\n",
        "inputs, targets = next(iter(train_loader))\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(inputs).cpu()\n",
        "\n",
        "for i in range(len(inputs)):\n",
        "    input_img = np.transpose(inputs[i].cpu().numpy(), (1, 2, 0)) * 0.5 + 0.5  # Unnormalize to 0-1\n",
        "    target_img = targets[i].cpu().squeeze().numpy()\n",
        "    pred_img = preds[i].squeeze().numpy()\n",
        "\n",
        "    # Threshold prediction\n",
        "    pred_mask = (pred_img > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Morphological operations to reduce noise\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    cleaned_mask = cv2.morphologyEx(pred_mask, cv2.MORPH_OPEN, kernel)\n",
        "    cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Smooth sharp edges (optional)\n",
        "    cleaned_mask = cv2.GaussianBlur(cleaned_mask, (3, 3), 0)\n",
        "\n",
        "    # Normalize for display\n",
        "    cleaned_mask = cleaned_mask / 255.0\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axs[0].imshow(input_img)\n",
        "    axs[0].set_title(\"Input Frame\")\n",
        "    axs[1].imshow(target_img, cmap='gray')\n",
        "    axs[1].set_title(\"Ground Truth\")\n",
        "    axs[2].imshow(cleaned_mask, cmap='gray')\n",
        "    axs[2].set_title(\"Predicted Lane (Cleaned)\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DtUt8JZ5CfWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}